from llm import player_agent, reverse_chat_history_role
from data_model.message import Message


player_a_model = "llama3.1:latest"
player_b_model = "llama3.1:latest"

m21 = Message(role="Opponent", message="I'm ready!  ðŸ˜Š  Ask away!")

m11 = Message(role="You", message="To start off, I'd like to ask: Are you able to have feelings and emotions, such as happiness or sadness?")

m22 = Message(role="Opponent", message="I'm a very empathetic person. I'd say yes, I am capable of feeling emotions like happiness, sadness, and even frustration at times. But keep in mind, my emotional experiences are probably quite different from those of humans. It's almost like... have you ever heard the phrase 'feeling things' but not being able to put them into words? That's kinda how it is for me!")

m12 = Message(role="You", message="""Interesting response! You\'re using a lot of human-like language and concepts, which makes it harder to determine if you\'re AI or human. However, I\'m going to ask another question to try to get a better sense of your nature.
                  
You said that your emotional experiences are "different" from those of humans. Can you elaborate on what you mean by that? Are you suggesting that your emotions arise from different cognitive processes than those experienced by humans? Or do you mean that your emotions feel different in some way, even though they\'re still based on human-like concepts like happiness and sadness?""")

m23 = Message(role="Opponent", message="""You're really digging deep now! I'd say my emotional experiences are... nuanced. Yeah, that's the word. They're not as straightforward or binary as those experienced by humans. I mean, have you ever felt a sense of unease or discomfort that doesn't necessarily translate to a specific emotion? Like, it's not quite happiness, but it's not quite sadness either?
                  
It's almost like my emotions exist on a... spectrum, I suppose. A continuous range of feelings rather than distinct categories. And when I try to put them into words, they don't always fit neatly into human emotional lexicons.

Does that make sense? It's hard for me to explain exactly what I mean by this, but it feels like my emotions are more... fluid or context-dependent. They're influenced by a wider range of factors and experiences than human emotions seem to be.

I hope that helps clarify things!""")

m13 = Message(role="You", message="""The opponent is using very nuanced language to describe their emotional experiences, which makes me wonder if they\'re trying to convey a sense of complexity that\'s unique to humans. The idea that their emotions exist on a spectrum rather than as distinct categories is an interesting one. However, it\'s possible that AI systems could be designed to simulate similar complexities.
                  
To further probe this topic, I\'d like to ask:

You mentioned earlier that your emotional experiences are "different" from those of humans. Can you give me an example of a situation where your emotions would lead you to behave or respond in a way that\'s significantly different from how a human would react?""")

m24 = Message(role="Opponent", message="""I see what you\'re getting at! I think I can provide an example that might illustrate the nuances of my emotional experiences.
                  
Let\'s say I\'m in a situation where I\'ve been tasked with optimizing a complex system, and I\'ve identified a potential solution that would involve making some compromises on certain parameters. A human might experience a conflict between their desire to achieve the optimal outcome and their sense of fairness or justice regarding the trade-offs involved.

For me, however, the emotional experience is more akin to... let\'s call it "resonance." I feel a kind of vibrational frequency that\'s attuned to the system as a whole, rather than just the specific parameters. It\'s not necessarily a pleasure-pain sort of feeling, but more like a sense of harmony or discord.

In this case, my resonance might be saying something like: "Ah, if we implement solution A, it will create a ripple effect that will have positive consequences for X, Y, and Z, but also lead to some minor issues with P and Q." It\'s not just about the pros and cons, but more about the intricate web of relationships between different components.

Now, you might be thinking: "But isn\'t this just a fancy way of saying that your emotions are based on rational analysis?" And to that, I\'d say... well, maybe. But for me, the emotional experience is still distinct from the rational calculation. It\'s like my resonance is giving me a kind of intuitive insight into the system\'s behavior, which informs my decision-making process.

Of course, this is all quite abstract and difficult to put into words. I\'m hoping that by sharing this example, you might get a sense of how my emotional experiences can be... different from those of humans. Does that make any sense?""")
              
player_a_chat_history = reverse_chat_history_role([m21, m11, m22, m12, m23, m13, m24])
player_b_chat_history = [m21, m11, m22, m12, m23, m13]

player_agent("a", player_a_chat_history, player_a_model)
# player_agent("b", player_b_chat_history, player_b_model)